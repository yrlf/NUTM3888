---
title: "major_project_3"
output: html_document
---

```{r library}
library(tidyverse)
#library(here)      # directory referencing
#library(readxl)    # reading Excel files
#library(janitor)   # data cleaning 
#library(stringr)   # string manipulation
library(tidyr)     # new tidy functions
library(knitr) # kable
#library(modi) # ok for multivariate outlier detection
library(caret)# low variance filter
# missing values
#library(naniar)
#library(knitr)
#library(ggpubr) # ggplot arrangement
#ploting 
library(gridExtra)
library(kableExtra)
#outlier
#library(univOutl)
# tree methods
#library(tourr)
#library(RColorBrewer)
#library(plotly)
#library(htmltools)
library(performanceEstimation)# for SMOTE
library(rpart)
library(rpart.plot)
library(rattle) #fancyRpartPlot
library(Rtsne)
library(randomForest)
library(neuralnet)
library(e1071)# SVM regression
library(mltools)
library(data.table)
library(skimr)
library(smotefamily)
library(broom)
library(jtools)
```


```{r load data}
load("tech_data.Rdata") # load cleaned data from John's code, make sure you have the Rdata file within the working directory
```

```{r dataset fliter}
#dat<-tech_biom %>% filter (AGEC >= 19, AGEC<=64, SMKSTAT==5)  # filter age and smoke status
dat<-tech_biom %>% filter (AGEC >= 19, AGEC<=64)  # filter age and smoke status
var_list<-c("BMISC","SEX","AGEC","DIABBC","HCHOLBC","HSUGBC","HYPBC", "SYSTOL","DIASTOL","TRIGRESB","FOLATREB","CHOLRESB","LDLRESB","HBA1PREB","GLUCFREB","ALTRESB","HDLCHREB") # add/remove variables that are interested
dat2<-dat %>% select (var_list) # select columns that we are interested
str(dat2) # 3488 obs x 13 variables

skim(dat2$DIABBC)
```


```{r creat obesity scores}
# dat3 contains obesity scores that are manually created for 4 diseases
# the higher score the more likely to be obesity

dat3<-dat2 %>% mutate(
  dia_score= ifelse(DIABBC==5, 0, ifelse(DIABBC==3, 1, ifelse(DIABBC==2, 2, ifelse(DIABBC==1, 3, NA)))),
  cho_score= ifelse(HCHOLBC==5, 0, ifelse(HCHOLBC==3, 1, ifelse(HCHOLBC==2, 2, ifelse(HCHOLBC==1, 3, NA)))),
  sug_score= ifelse(HSUGBC==5, 0, ifelse(HSUGBC==3, 1, ifelse(HSUGBC==2, 2, ifelse(HSUGBC==1, 3, NA)))),
  hyp_score= ifelse(HYPBC==5, 0, ifelse(HYPBC==3, 1, ifelse(HYPBC==2, 2, ifelse(HYPBC==1, 3, NA)))),
  final_score = dia_score+cho_score+sug_score+hyp_score
)

hist(dat3$dia_score) # the final score is highly unbalanced
nrow(dat3[which(dat3$DIABBC==5),]) # the final score of 2790 observations are 0

skim(dat3)

```


```{r SMOTE function from DWmR package}
SMOTE <- function(form,data,
                  perc.over=200,k=5,
                  perc.under=200,
                  learner=NULL,...
                  )
  
  # INPUTS:
  # form a model formula
  # data the original training set (with the unbalanced distribution)
  # minCl  the minority class label
  # per.over/100 is the number of new cases (smoted cases) generated
  #              for each rare case. If perc.over < 100 a single case
  #              is generated uniquely for a randomly selected perc.over
  #              of the rare cases
  # k is the number of neighbours to consider as the pool from where
  #   the new examples are generated
  # perc.under/100 is the number of "normal" cases that are randomly
  #                selected for each smoted case
  # learner the learning system to use.
  # ...  any learning parameters to pass to learner
{

  # the column where the target variable is
  tgt <- which(names(data) == as.character(form[[2]]))
  minCl <- levels(data[,tgt])[which.min(table(data[,tgt]))]
  
  # get the cases of the minority class
  minExs <- which(data[,tgt] == minCl)

  # generate synthetic cases from these minExs
  if (tgt < ncol(data)) {
      cols <- 1:ncol(data)
      cols[c(tgt,ncol(data))] <- cols[c(ncol(data),tgt)]
      data <-  data[,cols]
  }
  newExs <- smote.exs(data[minExs,],ncol(data),perc.over,k)
  if (tgt < ncol(data)) {
      newExs <- newExs[,cols]
      data <- data[,cols]
  }
  
  # get the undersample of the "majority class" examples
  selMaj <- sample((1:NROW(data))[-minExs],
                   as.integer((perc.under/100)*nrow(newExs)),
                   replace=T)

  # the final data set (the undersample+the rare cases+the smoted exs)
  newdataset <- rbind(data[selMaj,],data[minExs,],newExs)

  # learn a model if required
  if (is.null(learner)) return(newdataset)
  else do.call(learner,list(form,newdataset,...))
}



# ===================================================
# Obtain a set of smoted examples for a set of rare cases.
# L. Torgo, Feb 2010
# ---------------------------------------------------
smote.exs <- function(data,tgt,N,k)
  # INPUTS:
  # data are the rare cases (the minority "class" cases)
  # tgt is the name of the target variable
  # N is the percentage of over-sampling to carry out;
  # and k is the number of nearest neighours to use for the generation
  # OUTPUTS:
  # The result of the function is a (N/100)*T set of generated
  # examples with rare values on the target
{
  nomatr <- c()
  T <- matrix(nrow=dim(data)[1],ncol=dim(data)[2]-1)
  for(col in seq.int(dim(T)[2]))
    if (class(data[,col]) %in% c('factor','character')) {
      T[,col] <- as.integer(data[,col])
      nomatr <- c(nomatr,col)
    } else T[,col] <- data[,col]
  
  if (N < 100) { # only a percentage of the T cases will be SMOTEd
    nT <- NROW(T)
    idx <- sample(1:nT,as.integer((N/100)*nT))
    T <- T[idx,]
    N <- 100
  }

  p <- dim(T)[2]
  nT <- dim(T)[1]

  ranges <- apply(T,2,max)-apply(T,2,min)
  
  nexs <-  as.integer(N/100) # this is the number of artificial exs generated
                                        # for each member of T
  new <- matrix(nrow=nexs*nT,ncol=p)    # the new cases

  for(i in 1:nT) {

    # the k NNs of case T[i,]
    xd <- scale(T,T[i,],ranges)
    for(a in nomatr) xd[,a] <- xd[,a]==0
    dd <- drop(xd^2 %*% rep(1, ncol(xd)))
    kNNs <- order(dd)[2:(k+1)]

    for(n in 1:nexs) {
      # select randomly one of the k NNs
      neig <- sample(1:k,1)

      ex <- vector(length=ncol(T))

      # the attribute values of the generated case
      difs <- T[kNNs[neig],]-T[i,]
      new[(i-1)*nexs+n,] <- T[i,]+runif(1)*difs
      for(a in nomatr)
        new[(i-1)*nexs+n,a] <- c(T[kNNs[neig],a],T[i,a])[1+round(runif(1),0)]

    }
  }
  newCases <- data.frame(new)
  for(a in nomatr)
    newCases[,a] <- factor(newCases[,a],levels=1:nlevels(data[,a]),labels=levels(data[,a]))

  newCases[,tgt] <- factor(rep(data[1,tgt],nrow(newCases)),levels=levels(data[,tgt]))
  colnames(newCases) <- colnames(data)
  newCases
}
```



```{r smote}
dat33<-dat3[,1:17] # do NOT include DIABBC and sores other than dia_score
dat33<-na.omit(dat33)
table(dat33$DIABBC)


dat33.balanced <-smote(DIABBC~., dat33, perc.over=600, perc.under=2)
table(dat33.balanced$DIABBC)


dat33.balanced<-dat33.balanced %>% mutate(
  dia_score= ifelse(DIABBC==5, 0, 1),
)

dat33.balanced$dia_score<-as.factor(dat33.balanced$dia_score)


# 
# 
# dat33.balanced<-dat33.balanced[,-4]
# dat33.balanced
# 
# model<-lm(dia_score~., data=dat33.balanced)


set.seed(2021)
training.samples <- dat33.balanced$dia_score %>% 
  createDataPartition(p = 0.8, list = FALSE)
train.data  <- dat33.balanced[training.samples, ]
test.data <- dat33.balanced[-training.samples, ]

dat33.balanced

#model<-nnet::multinom(dia_score~.-DIABBC, data=train.data)
model<-nnet::multinom(dia_score~.-DIABBC, family=binomial, data=train.data)
predict_class<-predict(model,newdata=test.data)



length(predict_class)
length(test.data$DIABBC)

summ(model)
data.frame(predict_class)

table(predict_class, test.data$dia_score)

mean(predict_class==test.data$dia_score)





training.samples <- dat33$DIABBC %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data  <- dat33[training.samples, ]
test.data <- dat33[-training.samples, ]

model<-nnet::multinom(DIABBC~., data=train.data)


predict_class<-predict(model, newdata=test.data)
table(predict_class, test.data$DIABBC)



mean(predict_class==test.data$DIABBC)

# 
# summary(model)
```

```{r smote-k-fold cross-validation for linear regression }
set.seed(2021)
# Predict dia_score, drop other y and y-related variables
dat4<-subset(dat3, select=-c(DIABBC, HCHOLBC, HSUGBC, HYPBC, cho_score, sug_score, hyp_score, final_score)) 
# str(dat4)
# dat44<-dat4[dat4$dia_score>0,]
# str(dat44)
# remove NA values
dat4<-na.omit(dat4)
# set up k value for k-fold cross validation 
k_fold=10
# create k folds
folds<-createFolds(y=dat4$dia_score, k=k_fold)
# create a new vector to record test results
test_error_RMSE<-c() 

#table(dat33.balanced$HYPBC)

# K-fold cross-validation:
for (i in 1:k_fold){
  fold_test<-dat4[folds[[i]],] # select folds[[i]] as test test
  fold_train<-dat4[-folds[[i]],] # remaining is training set
  # linear regression using AIC
  M1<-lm(dia_score~., data=fold_train) # full model
  M0<-lm(dia_score~1, data=fold_train) # null model
  lm_model<-step(M1, scope=list(lower=M0, upper=M1),direction='backward', k=2) # backward selection from full model to null model
  fold_predict<-predict(lm_model, type='response', newdata=fold_test) # predict y
  test_error_RMSE[i] = RMSE(fold_predict, fold_test$dia_score) # calculate and record RMSE
}

summary(lm_model)
#model<-lm(dia_score~., data=dat4)
#summary(model)
avg_RMSE<-sum(test_error_RMSE)/k_fold
avg_RMSE
```

```{r k-fold cross-validation for linear regression }
set.seed(2021)
# Predict dia_score, drop other y and y-related variables
dat4<-subset(dat3, select=-c(DIABBC, HCHOLBC, HSUGBC, HYPBC, cho_score, sug_score, hyp_score, final_score)) 
# str(dat4)
# dat44<-dat4[dat4$dia_score>0,]
# str(dat44)
# remove NA values
dat4<-na.omit(dat4)
# set up k value for k-fold cross validation 
k_fold=10
# create k folds
folds<-createFolds(y=dat4$dia_score, k=k_fold)
# create a new vector to record test results
test_error_RMSE<-c() 

# K-fold cross-validation:
for (i in 1:k_fold){
  fold_test<-dat4[folds[[i]],] # select folds[[i]] as test test
  fold_train<-dat4[-folds[[i]],] # remaining is training set
  # linear regression using AIC
  M1<-lm(dia_score~., data=fold_train) # full model
  M0<-lm(dia_score~1, data=fold_train) # null model
  lm_model<-step(M1, scope=list(lower=M0, upper=M1),direction='backward', k=2) # backward selection from full model to null model
  fold_predict<-predict(lm_model, type='response', newdata=fold_test) # predict y
  test_error_RMSE[i] = RMSE(fold_predict, fold_test$dia_score) # calculate and record RMSE
}

summary(lm_model)
#model<-lm(dia_score~., data=dat4)
#summary(model)
avg_RMSE<-sum(test_error_RMSE)/k_fold
avg_RMSE
```


```{r k-fold cv for neural network}
# we use dat3 as a starting point for neural network analysis
dat5=dat3
# normalize all numeric variables
mystd <-function (x){
  x<- (x-mean(x, na.rm=TRUE))/sd(x, na.rm=TRUE)
}
# remove NA
dat5<-na.omit(dat5)
# normalize numeric values in dat5 such that they have mean value = 0 and std = 1
dat5_std<-dat5%>% mutate_if(is.numeric, list(mystd))
# create dataset with one hot encoding
dat5_one_hot <- one_hot(as.data.table(dat5_std))

# set up k value for k-fold cross validation 
k_fold=10
# set number of hiddne layers
hid_layer=5
# create k folds
folds<-createFolds(y=dat5_one_hot$dia_score, k=k_fold)

test_error_RMSE<-c() 

for (i in 1:k_fold){
  fold_test<-dat5_one_hot[folds[[i]],] # select folds[[i]] as test test
  fold_train<-dat5_one_hot[-folds[[i]],] # remaining is training set
  network<-neuralnet(dia_score~.-final_score-cho_score-sug_score-hyp_score, data=fold_train, hidden =hid_layer)
  fold_predict<-predict(network, fold_test)
  test_error_RMSE[i]<-RMSE(fold_predict, fold_test$dia_score) # calculate and record RMSE
}

avg_RMSE<-sum(test_error_RMSE)/k_fold
avg_RMSE

plot(network)
```


```{r random forest}
dat6 = dat3
dat6<-na.omit(dat6)

print(table(dat6$dia_score))

# set up k value for k-fold cross validation 
k_fold=10
# set number of hidden layers
hid_layer=5
# create k folds
folds<-createFolds(y=dat5_one_hot$dia_score, k=k_fold)

test_error_RMSE<-c() 

for (i in 1:k_fold){
  fold_test<-dat6[folds[[i]],] # select folds[[i]] as test test
  fold_train<-dat6[-folds[[i]],] # remaining is training set
  rf<-randomForest(dia_score ~ .-final_score-cho_score-sug_score-hyp_score, data=fold_train, ntree=100)
  fold_predict<-predict(rf, fold_test)
  test_error_RMSE[i]<-RMSE(fold_predict, fold_test$dia_score) # calculate and record RMSE
}
avg_RMSE<-sum(test_error_RMSE)/k_fold
avg_RMSE

# fit using a single tree
rp<-rpart(dia_score~.-final_score-cho_score-sug_score-hyp_score, 
      data = dat6,
      control=rpart.control(cp=0.0001, minsplit=5)
      )

fancyRpartPlot(rp,palettes=c("Oranges"), main="Dia_score Prediction")

```


